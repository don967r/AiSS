import streamlit as st
import pandas as pd
import geopandas as gpd
import folium
from folium.plugins import HeatMap
from streamlit_folium import st_folium
from datetime import timedelta, datetime
import io
from docx import Document
from docx.shared import Inches
import matplotlib.pyplot as plt # <-- –ù–æ–≤—ã–π –∏–º–ø–æ—Ä—Ç

# --- 1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –ó–∞–≥–æ–ª–æ–≤–æ–∫ ---
st.set_page_config(layout="wide", page_title="–ê–Ω–∞–ª–∏–∑ '–°—É–¥–Ω–æ-–ü—è—Ç–Ω–æ'")

# --- CSS –¥–ª—è —Ç–æ—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç—Å—Ç—É–ø–æ–≤ ---
st.markdown("""
<style>
/* –£–º–µ–Ω—å—à–∞–µ–º –æ–±—â–∏–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –æ—Ç—Å—Ç—É–ø—ã –¥–ª—è –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã */
div.block-container {
    padding-top: 2rem;
    padding-bottom: 1rem;
}
/* –£–º–µ–Ω—å—à–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–º–µ–∂—É—Ç–æ–∫ –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ */
div[data-testid="stVerticalBlock"] {
    gap: 0.8rem;
}
/* –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π –Ω–∏–∂–Ω–∏–π –æ—Ç—Å—Ç—É–ø —É –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å –∫–∞—Ä—Ç–æ–π */
div[data-testid="stFolium"] {
    margin-bottom: 0 !important;
}
/* –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Ç—Å—Ç—É–ø—ã —É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤–∏–¥–∞ */
h2 {
    margin-top: 1.5rem !important;
    margin-bottom: 0.5rem !important;
}
/* –ó–∞—Å—Ç–∞–≤–ª—è–µ—Ç –ø–∞–Ω–µ–ª—å –≤–∫–ª–∞–¥–∫–∏ —Å–∂–∏–º–∞—Ç—å—Å—è –¥–æ –≤—ã—Å–æ—Ç—ã —Å–≤–æ–µ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ */
div[data-testid="stTabsPanel"] {
    padding-top: 1rem;
    padding-bottom: 0 !important;
    min-height: 0;
}
</style>
""", unsafe_allow_html=True)

# --- –ó–∞–¥–∞–µ–º –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ ---
SPILLS_FILE_PATH = 'fields2.geojson'
AIS_FILE_PATH = 'generated_ais_data.csv'
ROUTES_FILE_PATH = 'routs.geojson'

# --- 2. –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ ---
st.sidebar.header("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")

time_window_hours = st.sidebar.slider(
    "–í—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –ø–æ–∏—Å–∫–∞ (—á–∞—Å—ã –¥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è):",
    min_value=1, max_value=168, value=24, step=1,
    help="–ò—Å–∫–∞—Ç—å —Å—É–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –≤ –∑–æ–Ω–µ —Ä–∞–∑–ª–∏–≤–∞ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –î–û –µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è."
)
date_range = st.sidebar.date_input(
    "–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
    value=(datetime(2022, 1, 1), datetime(2025, 7, 15)),
    min_value=datetime(2000, 1, 1),
    max_value=datetime(2030, 12, 31),
    help="–í—ã–±–µ—Ä–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–∑–ª–∏–≤–æ–≤ –∏ AIS-–¥–∞–Ω–Ω—ã—Ö."
)
st.sidebar.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ—è–º–∏")
show_spills = st.sidebar.checkbox("–ü—è—Ç–Ω–∞ —Ä–∞–∑–ª–∏–≤–æ–≤", value=True)
show_ships = st.sidebar.checkbox("–°—É–¥–∞-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã", value=True)
show_routes = st.sidebar.checkbox("–°—É–¥–æ–≤—ã–µ —Ç—Ä–∞—Å—Å—ã", value=True)

# --- 3. –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö ---
@st.cache_data
def load_spills_data(file_path):
    try:
        gdf = gpd.read_file(file_path)
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å GeoJSON —Ñ–∞–π–ª '{file_path}'. –û—à–∏–±–∫–∞: {e}")
        return gpd.GeoDataFrame()
    required_cols = ['slick_name', 'area_sys']
    if not all(col in gdf.columns for col in required_cols):
        missing = [col for col in required_cols if col not in gdf.columns]
        st.error(f"–í GeoJSON –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {', '.join(missing)}")
        return gpd.GeoDataFrame()
    gdf.rename(columns={'slick_name': 'spill_id', 'area_sys': 'area_sq_km'}, inplace=True)
    if 'date' in gdf.columns and 'time' in gdf.columns:
        gdf['detection_date'] = pd.to_datetime(gdf['date'] + ' ' + gdf['time'], errors='coerce')
    else:
        gdf['detection_date'] = pd.to_datetime(gdf['spill_id'], format='%Y-%m-%d_%H:%M:%S', errors='coerce')
    gdf.dropna(subset=['detection_date'], inplace=True)
    if gdf.crs is None:
        gdf.set_crs("EPSG:4326", inplace=True)
    else:
        gdf = gdf.to_crs("EPSG:4326")
    return gdf

@st.cache_data
def load_ais_data(file_path):
    try:
        df = pd.read_csv(file_path, low_memory=False)
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV —Ñ–∞–π–ª '{file_path}'. –û—à–∏–±–∫–∞: {e}")
        return gpd.GeoDataFrame()
    required_cols = ['mmsi', 'latitude', 'longitude', 'BaseDateTime']
    if not all(col in df.columns for col in required_cols):
        missing = [col for col in required_cols if col not in df.columns]
        st.error(f"–í CSV —Ñ–∞–π–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing)}")
        return gpd.GeoDataFrame()
    df['timestamp'] = pd.to_datetime(df['BaseDateTime'], errors='coerce')
    df.dropna(subset=['timestamp', 'latitude', 'longitude'], inplace=True)
    gdf = gpd.GeoDataFrame(
        df,
        geometry=gpd.points_from_xy(df.longitude, df.latitude),
        crs="EPSG:4326"
    )
    return gdf

@st.cache_data
def load_routes_data(file_path):
    try:
        gdf = gpd.read_file(file_path)
        if gdf.crs is None:
            gdf.set_crs("EPSG:4326", inplace=True)
        else:
            gdf = gdf.to_crs("EPSG:4326")
        return gdf
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª —Ç—Ä–∞—Å—Å '{file_path}'. –°–ª–æ–π –Ω–µ –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω. –û—à–∏–±–∫–∞: {e}")
        return gpd.GeoDataFrame()

def find_candidates(spills_gdf, vessels_gdf, time_window_hours):
    if spills_gdf.empty or vessels_gdf.empty:
        return gpd.GeoDataFrame()
    candidates = gpd.sjoin(vessels_gdf, spills_gdf, predicate='within')
    if candidates.empty:
        return gpd.GeoDataFrame()
    time_delta = timedelta(hours=time_window_hours)
    candidates = candidates[
        (candidates['timestamp'] <= candidates['detection_date']) &
        (candidates['timestamp'] >= candidates['detection_date'] - time_delta)
    ]
    return candidates

# --- –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ì–ï–ù–ï–†–ê–¶–ò–ò –û–¢–ß–ï–¢–ê ---

# >>> –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ì–ï–ù–ï–†–ê–¶–ò–ò –ì–†–ê–§–ò–ö–ê
def create_incident_plot(spill_data, candidates_data):
    """
    –°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞ (–ø—è—Ç–Ω–æ + —Å—É–¥–∞) —Å –ø–æ–º–æ—â—å—é Matplotlib.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ –±–∞–π—Ç–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞.
    """
    fig, ax = plt.subplots(figsize=(10, 8))

    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∫–æ–Ω—Ç—É—Ä–∞ –ø—è—Ç–Ω–∞
    gpd.GeoSeries([spill_data['geometry']]).plot(
        ax=ax,
        edgecolor='red',
        facecolor='red',
        alpha=0.3,
        linewidth=1.5,
        label=f"–ü—è—Ç–Ω–æ {spill_data['spill_id']}"
    )

    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å—É–¥–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    if not candidates_data.empty:
        candidates_data.plot(
            ax=ax,
            marker='o',
            color='blue',
            markersize=50,
            label='–°—É–¥–∞-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã'
        )
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ MMSI –∫ —Ç–æ—á–∫–∞–º —Å—É–¥–æ–≤
        for idx, row in candidates_data.iterrows():
            ax.text(row.geometry.x, row.geometry.y, f" {row['mmsi']}", fontsize=9, ha='left', color='navy')


    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞
    ax.set_title(f"–ö–∞—Ä—Ç–∞-—Å—Ö–µ–º–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞: {spill_data['spill_id']}", fontsize=14)
    ax.set_xlabel("–î–æ–ª–≥–æ—Ç–∞")
    ax.set_ylabel("–®–∏—Ä–æ—Ç–∞")
    ax.grid(True, linestyle='--', alpha=0.6)
    ax.legend()
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–≤–Ω—ã–π –º–∞—Å—à—Ç–∞–± –¥–ª—è –æ—Å–µ–π, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∏—Å–∫–∞–∂–µ–Ω–∏–π
    ax.set_aspect('equal', adjustable='box')
    plt.tight_layout()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫ –≤ –±–∞–π—Ç–æ–≤—ã–π –±—É—Ñ–µ—Ä –≤ –ø–∞–º—è—Ç–∏
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=150)
    buf.seek(0)
    plt.close(fig) # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∏–≥—É—Ä—É, —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –ø–∞–º—è—Ç—å

    return buf.getvalue()

def strfdelta(tdelta, fmt):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è timedelta."""
    d = {"days": tdelta.days}
    d["hours"], rem = divmod(tdelta.seconds, 3600)
    d["minutes"], d["seconds"] = divmod(rem, 60)
    return fmt.format(**d)

def generate_docx_report(spill_data, candidates_data, prime_suspect_data, historical_data, plot_bytes=None):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ DOCX, –≤–∫–ª—é—á–∞—è –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫."""
    doc = Document()
    doc.add_heading('–û–¢–ß–ï–¢ –ü–û –ê–ù–ê–õ–ò–ó–£ –°–í–Ø–ó–ò "–°–£–î–ù–û-–ü–Ø–¢–ù–û"', level=1)
    
    doc.add_paragraph(f"–î–∞—Ç–∞ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {datetime.now().strftime('%d.%m.%Y')}")
    doc.add_paragraph(f"ID –æ—Ç—á–µ—Ç–∞: SP-{spill_data['spill_id'].replace(':', '-')}")
    doc.add_paragraph()

    doc.add_heading('1. –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û–ë –ò–ù–¶–ò–î–ï–ù–¢–ï (–ü–Ø–¢–ù–ï)', level=2)
    doc.add_paragraph(f"ID –ø—è—Ç–Ω–∞ (spill_id): {spill_data['spill_id']}")
    doc.add_paragraph(f"–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è: {spill_data['detection_date'].strftime('%Y-%m-%d %H:%M:%S')}")
    doc.add_paragraph(f"–ü–ª–æ—â–∞–¥—å –ø—è—Ç–Ω–∞ (–∫–º¬≤): {spill_data.get('area_sq_km', 0):.2f}")
    
    centroid = spill_data['geometry'].centroid
    doc.add_paragraph(f"–ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (—Ü–µ–Ω—Ç—Ä–æ–∏–¥): Lat {centroid.y:.4f}, Lon {centroid.x:.4f}")

    if plot_bytes:
        try:
            image_stream = io.BytesIO(plot_bytes)
            doc.add_picture(image_stream, width=Inches(6.0))
            p = doc.add_paragraph(f"–†–∏—Å. 1. –ö–∞—Ä—Ç–∞-—Å—Ö–µ–º–∞ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –ø—è—Ç–Ω–∞ {spill_data['spill_id']} –∏ —Å—É–¥–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.")
            p.style = 'Caption'
        except Exception as e:
            doc.add_paragraph(f"[–ù–µ —É–¥–∞–ª–æ—Å—å –≤—Å—Ç–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}]")
    
    doc.add_heading('2. –ü–ê–†–ê–ú–ï–¢–†–´ –ê–ù–ê–õ–ò–ó–ê', level=2)
    doc.add_paragraph(f"–í—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –ø–æ–∏—Å–∫–∞: {time_window_hours} —á–∞—Å–æ–≤ –¥–æ –º–æ–º–µ–Ω—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø—è—Ç–Ω–∞.")
    doc.add_paragraph("–ö—Ä–∏—Ç–µ—Ä–∏–π —Å–≤—è–∑–∏: –°—É–¥–Ω–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º, –µ—Å–ª–∏ –µ–≥–æ AIS-–ø–æ–∑–∏—Ü–∏—è –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ –≤–Ω—É—Ç—Ä–∏ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –≥—Ä–∞–Ω–∏—Ü –ø—è—Ç–Ω–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º –æ–∫–Ω–µ.")

    doc.add_heading('3. –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê: –°–£–î–ê-–ö–ê–ù–î–ò–î–ê–¢–´', level=2)
    if not candidates_data.empty:
        doc.add_paragraph("–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—É–¥–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:")
        table = doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'
        hdr_cells = table.rows[0].cells
        hdr_cells[0].text = 'MMSI —Å—É–¥–Ω–∞'
        hdr_cells[1].text = '–ù–∞–∑–≤–∞–Ω–∏–µ —Å—É–¥–Ω–∞'
        hdr_cells[2].text = '–í—Ä–µ–º—è –ø—Ä–æ—Ö–æ–¥–∞'
        hdr_cells[3].text = '–í—Ä–µ–º—è –¥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è'

        for _, row in candidates_data.iterrows():
            row_cells = table.add_row().cells
            row_cells[0].text = str(row.get('mmsi', 'N/A'))
            row_cells[1].text = str(row.get('vessel_name', '–ò–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ'))
            row_cells[2].text = row['timestamp'].strftime('%Y-%m-%d %H:%M')
            time_to_detection = spill_data['detection_date'] - row['timestamp']
            row_cells[3].text = strfdelta(time_to_detection, "{hours} —á {minutes} –º–∏–Ω")

        doc.add_paragraph()
        doc.add_heading('–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞', level=3)
        if prime_suspect_data is not None and not prime_suspect_data.empty:
            suspect = prime_suspect_data.iloc[0]
            doc.add_paragraph(f"–°—É–¥–Ω–æ: {suspect.get('vessel_name', '–ò–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ')} (MMSI: {suspect['mmsi']})")
            doc.add_paragraph(f"–í—Ä–µ–º—è –¥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è: {strfdelta(suspect['time_to_detection'], '{hours} —á {minutes} –º–∏–Ω')}")
            if historical_data:
                 doc.add_paragraph(f"–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {historical_data.get('incident_count', 0)} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤, –æ–±—â–∞—è –ø–ª–æ—â–∞–¥—å {historical_data.get('total_area_sq_km', 0):.2f} –∫–º¬≤.")
        else:
            doc.add_paragraph("–û—Å–Ω–æ–≤–Ω–æ–π –∫–∞–Ω–¥–∏–¥–∞—Ç (—Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º –¥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è) –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω.")
    else:
        doc.add_paragraph("–°—É–¥–∞-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º –æ–∫–Ω–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

    doc.add_heading('4. –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï', level=2)
    conclusion_text = (
        f"1. –§–∞–∫—Ç: {spill_data['detection_date'].strftime('%d.%m.%Y')} –±—ã–ª–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ (ID: {spill_data['spill_id']}) "
        f"–ø–ª–æ—â–∞–¥—å—é {spill_data.get('area_sq_km', 0):.2f} –∫–º¬≤.\n"
        f"2. –ê–Ω–∞–ª–∏–∑: –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö AIS –∑–∞ {time_window_hours} —á–∞—Å–æ–≤ –¥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –±—ã–ª–æ –≤—ã—è–≤–ª–µ–Ω–æ {len(candidates_data)} —Å—É–¥–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.\n"
    )
    if prime_suspect_data is not None and not prime_suspect_data.empty:
        suspect = prime_suspect_data.iloc[0]
        conclusion_text += (
            f"3. –û—Å–Ω–æ–≤–Ω–æ–π –≤—ã–≤–æ–¥: –ù–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è —Å—É–¥–Ω–æ "
            f"{suspect.get('vessel_name', '–ò–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ')} (MMSI: {suspect['mmsi']}), —Ç–∞–∫ –∫–∞–∫ –æ–Ω–æ –ø—Ä–æ—à–ª–æ —á–µ—Ä–µ–∑ –¥–∞–Ω–Ω—É—é —Ç–æ—á–∫—É –∑–∞ "
            f"{strfdelta(suspect['time_to_detection'], '{hours} —á {minutes} –º–∏–Ω')} –¥–æ —Ñ–∏–∫—Å–∞—Ü–∏–∏ –ø—è—Ç–Ω–∞."
        )
    else:
        conclusion_text += "3. –û—Å–Ω–æ–≤–Ω–æ–π –≤—ã–≤–æ–¥: –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å—É–¥–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤."
    doc.add_paragraph(conclusion_text)

    doc.add_heading('5. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò', level=2)
    if prime_suspect_data is not None and not prime_suspect_data.empty:
        suspect = prime_suspect_data.iloc[0]
        reco_text = (
            f"- –ü—Ä–æ–≤–µ—Å—Ç–∏ —É–≥–ª—É–±–ª–µ–Ω–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ —Å—É–¥–Ω–∞ {suspect.get('vessel_name', '–ò–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ')} (MMSI: {suspect['mmsi']}).\n"
            "- –ó–∞–ø—Ä–æ—Å–∏—Ç—å —Å—É–¥–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –∑–∞–ø–∏—Å–∏ –±–æ—Ä—Ç–æ–≤—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥, –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω—Ü–∏–¥–µ–Ω—Ç—É."
        )
        doc.add_paragraph(reco_text)
    else:
        doc.add_paragraph("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.")
    
    file_stream = io.BytesIO()
    doc.save(file_stream)
    file_stream.seek(0)
    return file_stream.getvalue()

# --- 4. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
spills_gdf = load_spills_data(SPILLS_FILE_PATH)
vessels_gdf = load_ais_data(AIS_FILE_PATH)
routes_gdf = load_routes_data(ROUTES_FILE_PATH)

if spills_gdf.empty or vessels_gdf.empty:
    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö (—Ä–∞–∑–ª–∏–≤—ã, AIS). –ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
    st.stop()

if len(date_range) == 2:
    start_date, end_date = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1]) + pd.Timedelta(days=1)
    spills_gdf = spills_gdf[(spills_gdf['detection_date'] >= start_date) & (spills_gdf['detection_date'] <= end_date)]
    vessels_gdf = vessels_gdf[(vessels_gdf['timestamp'] >= start_date) & (vessels_gdf['timestamp'] <= end_date)]

vessel_options = vessels_gdf[['mmsi']].drop_duplicates()
if 'vessel_name' in vessels_gdf.columns:
    vessel_options = vessels_gdf[['mmsi', 'vessel_name']].drop_duplicates()
    vessel_options['display'] = vessel_options.apply(
        lambda x: f"{x['vessel_name']} (MMSI: {x['mmsi']})" if pd.notnull(x['vessel_name']) else f"MMSI: {x['mmsi']}", axis=1
    )
else:
    vessel_options['display'] = vessel_options['mmsi'].apply(lambda x: f"MMSI: {x}")

selected_vessels_display = st.sidebar.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Å—É–¥–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:",
    options=vessel_options['display'].tolist(),
    help="–§–∏–ª—å—Ç—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –∫–∞—Ä—Ç–µ –∏ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Å—É–¥–∞–º."
)

filtered_routes_gdf = routes_gdf.copy()
if selected_vessels_display:
    selected_mmsi = vessel_options[vessel_options['display'].isin(selected_vessels_display)]['mmsi'].tolist()
    vessels_gdf = vessels_gdf[vessels_gdf['mmsi'].isin(selected_mmsi)]
    if not filtered_routes_gdf.empty and 'mmsi' in filtered_routes_gdf.columns:
        filtered_routes_gdf = filtered_routes_gdf[filtered_routes_gdf['mmsi'].isin(selected_mmsi)]

# --- 5. –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞—Ä—Ç—ã –∏ —Ç–∞–±–ª–∏—Ü—ã ---
with st.container(border=False):
    st.header("–ö–∞—Ä—Ç–∞ —Ä–∞–∑–ª–∏–≤–æ–≤ –∏ —Å—É–¥–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
    
    map_center = [67.63778, 53.00667] 
    map_tiles = "CartoDB dark_matter"
    m = folium.Map(location=map_center, zoom_start=3, tiles=map_tiles, attributionControl=False)
    
    candidates_df = gpd.GeoDataFrame()
    if spills_gdf.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Ä–∞–∑–ª–∏–≤–∞—Ö –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –¥–∞—Ç.")
    else:
        candidates_df = find_candidates(spills_gdf, vessels_gdf, time_window_hours)
        spills_fg = folium.FeatureGroup(name="–ü—è—Ç–Ω–∞ —Ä–∞–∑–ª–∏–≤–æ–≤", show=show_spills)
        for _, row in spills_gdf.iterrows():
            folium.GeoJson(
                row['geometry'],
                style_function=lambda x: {'fillColor': '#B22222', 'color': 'black', 'weight': 1.5, 'fillOpacity': 0.6},
                tooltip=f"<b>–ü—è—Ç–Ω–æ:</b> {row.get('spill_id', 'N/A')}<br>"
                        f"<b>–í—Ä–µ–º—è:</b> {row['detection_date'].strftime('%Y-%m-%d %H:%M')}<br>"
                        f"<b>–ü–ª–æ—â–∞–¥—å:</b> {row.get('area_sq_km', 0):.2f} –∫–º¬≤"
            ).add_to(spills_fg)
        spills_fg.add_to(m)

        candidate_vessels_fg = folium.FeatureGroup(name="–°—É–¥–∞-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã", show=show_ships)
        if not candidates_df.empty:
            for _, row in candidates_df.iterrows():
                vessel_name = row.get('vessel_name', '–ò–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ')
                folium.Marker(
                    location=[row.geometry.y, row.geometry.x],
                    tooltip=f"<b>–°—É–¥–Ω–æ:</b> {vessel_name} (MMSI: {row['mmsi']})<br>"
                            f"<b>–í—Ä–µ–º—è –ø—Ä–æ—Ö–æ–¥–∞:</b> {row['timestamp'].strftime('%Y-%m-%d %H:%M')}<br>"
                            f"<b>–í–Ω—É—Ç—Ä–∏ –ø—è—Ç–Ω–∞:</b> {row['spill_id']}",
                    icon=folium.Icon(color='blue', icon='ship', prefix='fa')
                ).add_to(candidate_vessels_fg)
        candidate_vessels_fg.add_to(m)
        
        routes_fg = folium.FeatureGroup(name="–°—É–¥–æ–≤—ã–µ —Ç—Ä–∞—Å—Å—ã", show=show_routes)
        if not filtered_routes_gdf.empty:
            for _, row in filtered_routes_gdf.iterrows():
                tooltip_text = f"<b>–¢—Ä–µ–∫ —Å—É–¥–Ω–∞ (MMSI: {row.get('mmsi', 'N/A')})</b>"
                folium.GeoJson(
                    row['geometry'],
                    style_function=lambda x: {'color': '#007FFF', 'weight': 2.5, 'opacity': 0.7},
                    tooltip=tooltip_text
                ).add_to(routes_fg)
        routes_fg.add_to(m)

    folium.LayerControl().add_to(m) 
    st_folium(m, width=1200, height=400, returned_objects=[])

    st.header(f"–¢–∞–±–ª–∏—Ü–∞ —Å—É–¥–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö {time_window_hours} —á–∞—Å–æ–≤)")
    if candidates_df.empty:
        st.info("–í –∑–∞–¥–∞–Ω–Ω–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º –æ–∫–Ω–µ –∏ —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤ —Å—É–¥–∞-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
    else:
        report_df = candidates_df.drop_duplicates(subset=['spill_id', 'mmsi'])
        desired_cols = ['spill_id', 'mmsi', 'vessel_name', 'timestamp', 'detection_date', 'area_sq_km']
        existing_cols = [col for col in desired_cols if col in report_df.columns]
        display_df = report_df[existing_cols].copy()
        rename_dict = {
            'spill_id': 'ID –ü—è—Ç–Ω–∞', 'mmsi': 'MMSI –°—É–¥–Ω–∞', 'vessel_name': '–ù–∞–∑–≤–∞–Ω–∏–µ —Å—É–¥–Ω–∞',
            'timestamp': '–í—Ä–µ–º—è –ø—Ä–æ—Ö–æ–¥–∞', 'detection_date': '–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è', 'area_sq_km': '–ü–ª–æ—â–∞–¥—å, –∫–º¬≤'
        }
        display_df.rename(columns=rename_dict, inplace=True)
        st.dataframe(display_df.sort_values(by='–í—Ä–µ–º—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è', ascending=False).reset_index(drop=True), use_container_width=True)

# --- 6. –ë–ª–æ–∫ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π ---
with st.container(border=False):
    st.header("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞")
    tab1, tab2, tab3 = st.tabs(["üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ —Å—É–¥–∞–º", "üìç –ì–æ—Ä—è—á–∏–µ —Ç–æ—á–∫–∏ (Hotspots)", "üîç –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞–º"])

    candidates_df_for_analytics = find_candidates(spills_gdf, vessels_gdf, time_window_hours) if not spills_gdf.empty else gpd.GeoDataFrame()
    prime_suspects_df = pd.DataFrame()

    with tab1:
        if not candidates_df_for_analytics.empty:
            unique_incidents = candidates_df_for_analytics.drop_duplicates(subset=['mmsi', 'spill_id'])
            ship_names = unique_incidents[['mmsi', 'vessel_name']].drop_duplicates('mmsi')
            st.subheader("–ê–Ω—Ç–∏—Ä–µ–π—Ç–∏–Ω–≥ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø—è—Ç–µ–Ω")
            ship_incident_counts = unique_incidents.groupby('mmsi').size().reset_index(name='incident_count').sort_values('incident_count', ascending=False)
            st.dataframe(pd.merge(ship_incident_counts, ship_names, on='mmsi', how='left'), use_container_width=True)
            st.subheader("–ê–Ω—Ç–∏—Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —Å—É–º–º–∞—Ä–Ω–æ–π –ø–ª–æ—â–∞–¥–∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø—è—Ç–µ–Ω (–∫–º¬≤)")
            ship_area_sum = unique_incidents.groupby('mmsi')['area_sq_km'].sum().reset_index(name='total_area_sq_km').sort_values('total_area_sq_km', ascending=False)
            st.dataframe(pd.merge(ship_area_sum, ship_names, on='mmsi', how='left'), use_container_width=True)
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø–æ —Å—É–¥–∞–º.")

    with tab2:
        st.subheader("–ö–∞—Ä—Ç–∞ '–≥–æ—Ä—è—á–∏—Ö —Ç–æ—á–µ–∫' —Ä–∞–∑–ª–∏–≤–æ–≤")
        if spills_gdf.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞—Ä—Ç—ã –≥–æ—Ä—è—á–∏—Ö —Ç–æ—á–µ–∫.")
        else:
            map_center = [67.638, 53.005]
            m_heatmap = folium.Map(location=map_center, zoom_start=3, tiles=map_tiles, attributionControl=False)
            heat_data = [[point.xy[1][0], point.xy[0][0], row['area_sq_km']] for _, row in spills_gdf.iterrows() for point in [row['geometry'].centroid]]
            HeatMap(heat_data, radius=15, blur=20).add_to(m_heatmap)
            st_folium(m_heatmap, width=1200, height=350, returned_objects=[])

    with tab3:
        if not candidates_df_for_analytics.empty:
            unique_incidents = candidates_df_for_analytics.drop_duplicates(subset=['mmsi', 'spill_id'])
            st.subheader("–ü—è—Ç–Ω–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å—É–¥–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
            spill_candidate_counts = candidates_df_for_analytics.groupby('spill_id')['mmsi'].nunique().reset_index(name='candidate_count').sort_values('candidate_count', ascending=False)
            st.dataframe(spill_candidate_counts, use_container_width=True)
            
            st.subheader("–ì–ª–∞–≤–Ω—ã–µ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–µ (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è)")
            candidates_df_for_analytics['time_to_detection'] = candidates_df_for_analytics['detection_date'] - candidates_df_for_analytics['timestamp']
            prime_suspects_idx = candidates_df_for_analytics.groupby('spill_id')['time_to_detection'].idxmin()
            prime_suspects_df = candidates_df_for_analytics.loc[prime_suspects_idx]
            display_cols = ['spill_id', 'mmsi', 'vessel_name', 'time_to_detection', 'area_sq_km']
            st.dataframe(prime_suspects_df[[col for col in display_cols if col in prime_suspects_df]].sort_values('area_sq_km', ascending=False), use_container_width=True)
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø–æ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞–º.")

# --- 7. –£–õ–£–ß–®–ï–ù–ù–´–ô –ë–õ–û–ö –§–û–†–ú–ò–†–û–í–ê–ù–ò–Ø –û–¢–ß–ï–¢–ê –° –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ú –ì–†–ê–§–ò–ö–û–ú ---
st.header("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ –∏–Ω—Ü–∏–¥–µ–Ω—Ç—É")
with st.expander("üñ®Ô∏è –ù–∞–∂–º–∏—Ç–µ, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –∏–Ω—Ü–∏–¥–µ–Ω—Ç –∏ —Å–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç", expanded=False):

    if not candidates_df_for_analytics.empty:
        # --- –ß–∞—Å—Ç—å 1: –í—ã–±–æ—Ä –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞ ---
        spills_with_candidates = candidates_df_for_analytics[['spill_id', 'detection_date', 'area_sq_km']].drop_duplicates(subset=['spill_id'])
        candidate_counts = candidates_df_for_analytics.groupby('spill_id')['mmsi'].nunique().reset_index(name='candidate_count')
        
        reportable_incidents_df = pd.merge(spills_with_candidates, candidate_counts, on='spill_id').sort_values(by='detection_date', ascending=False)
        reportable_incidents_df.rename(columns={
            'spill_id': 'ID –ü—è—Ç–Ω–∞', 'detection_date': '–î–∞—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è',
            'area_sq_km': '–ü–ª–æ—â–∞–¥—å, –∫–º¬≤', 'candidate_count': '–ö–æ–ª-–≤–æ –∫–∞–Ω–¥.'
        }, inplace=True)

        st.info("–ù–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞–π–¥–µ–Ω—ã —Å—É–¥–∞-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã. –í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞.")
        st.dataframe(reportable_incidents_df.reset_index(drop=True), use_container_width=True)

        reportable_incidents_df['display_option'] = reportable_incidents_df.apply(
            lambda row: f"ID: {row['ID –ü—è—Ç–Ω–∞']} (–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {row['–ö–æ–ª-–≤–æ –∫–∞–Ω–¥.']})", axis=1
        )
        
        selected_option = st.radio(
            "–®–∞–≥ 1: –í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞",
            options=reportable_incidents_df['display_option'].tolist(),
            key="report_selection_radio"
        )

        if selected_option:
            # --- –ß–∞—Å—Ç—å 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ ---
            selected_spill_id = selected_option.split(' ')[1]
            spill_row = spills_gdf[spills_gdf['spill_id'] == selected_spill_id].iloc[0]
            candidates_for_spill = candidates_df_for_analytics[candidates_df_for_analytics['spill_id'] == selected_spill_id]
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –≤ –ø–∞–º—è—Ç–∏
            plot_bytes = create_incident_plot(spill_row, candidates_for_spill)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–∞
            prime_suspect_for_spill = prime_suspects_df[prime_suspects_df['spill_id'] == selected_spill_id] if not prime_suspects_df.empty else pd.DataFrame()
            
            historical_data = {}
            if not prime_suspect_for_spill.empty:
                suspect_mmsi = prime_suspect_for_spill.iloc[0]['mmsi']
                unique_incidents = candidates_df_for_analytics.drop_duplicates(subset=['mmsi', 'spill_id'])
                ship_incident_counts = unique_incidents.groupby('mmsi').size().reset_index(name='incident_count')
                ship_area_sum = unique_incidents.groupby('mmsi')['area_sq_km'].sum().reset_index(name='total_area_sq_km')
                incident_count = ship_incident_counts[ship_incident_counts['mmsi'] == suspect_mmsi]
                area_sum = ship_area_sum[ship_area_sum['mmsi'] == suspect_mmsi]
                historical_data['incident_count'] = incident_count['incident_count'].iloc[0] if not incident_count.empty else 0
                historical_data['total_area_sq_km'] = area_sum['total_area_sq_km'].iloc[0] if not area_sum.empty else 0

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∞–º–æ–≥–æ DOCX —Ñ–∞–π–ª–∞
            report_bytes = generate_docx_report(spill_row, candidates_for_spill, prime_suspect_for_spill, historical_data, plot_bytes)

            st.markdown("---")
            st.subheader("–®–∞–≥ 2: –°–∫–∞—á–∞–π—Ç–µ –≥–æ—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç")
            st.download_button(
                label="‚úÖ –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç (.docx)",
                data=report_bytes,
                file_name=f"–û—Ç—á–µ—Ç_{selected_spill_id.replace(':', '_')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
    else:
        st.info("–î–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤ —Å —Å—É–¥–∞–º–∏-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º–∏ –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º –æ–∫–Ω–µ –∏ —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤.")